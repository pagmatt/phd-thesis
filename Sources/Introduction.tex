%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\glsresetall
\chapter{Introduction}
\label{ch:intro}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The significance of mobile networks in modern society is underscored by their paramount role in facilitating social, professional, and educational interactions. The recent COVID-19 pandemic has served as a bitter reminder of this critical importance, highlighting how the absence of Internet connectivity can represent a conspicuous hindrance to our daily lives~\cite{feldmann2021year}.
However, the current generation of cellular networks, i.e., \gls{5g}, are found wanting in providing adequate broadband coverage to rural regions~\cite{yaacoub2020key}. Furthermore, even in technologically advanced nations, cellular infrastructures often fall short of meeting the stringent reliability, availability, and responsiveness requirements of future mobile networks~\cite{giordani2020non}. The latter will be asked to remain operational even in the occurrence of natural disasters and cyberattacks, emphasizing the need for solutions which offer reliability from both a technological and a sociopolitical standpoint.
Indeed, recent geopolitical turmoils have expanded the scope of conflict to include the cyberspace, emphasizing the imperative of maintaining uninterrupted connectivity in emergency situations. In these contexts, connectivity outages can compromise the delivery of critical services, inflict significant economic damage, and even result in loss of lives~\cite{internet_ukr_afg}.

In response to the pressing need for reliable wireless connectivity, the \gls{itu} foresees a future where ubiquitous broadband coverage will be achieved by 2030~\cite{imt2030}. This vision is driven by the imperative to provide seamless connectivity to both humans and an increasingly vast array of intelligent devices, including wearables, autonomous vehicles, \glspl{uas}, and robots~\cite{mozaffari2018beyond}.
At the same time, the advent of novel use cases such as holographic communications, \gls{xr}, and tactile applications will further exacerbate the requirements for peak throughput and latency identified for the 5G's \gls{embb} and \gls{urllc} use cases. 

To achieve these ambitious goals, future cellular systems will continue to evolve and enhance the 5G network paradigm, which has revolutionized the wireless landscape by introducing flexible virtualized architectures, the support for \gls{mmwave} communications, and the adoption of \gls{mimo} technologies~\cite{ghosh20195g}. 
Notably, both academic and industry researchers are investigating how to fully reap the benefits of \glspl{mmwave}, with plans to allocate additional spectrum towards the \gls{thz} band~\cite{9887921}, and to design \gls{ai}-native networks~\cite{letaief2019roadmap}.

The THz and mmWave frequency bands hold significant promise as a means to achieve peak data rates exceeding Tb/s, as envisioned by the ITU~\cite{imt2030}. However, this portion of the spectrum is hampered by harsh propagation characteristics that make it challenging to realize its full potential.
Specifically, the THz and mmWave bands are plagued by a pronounced free-space propagation loss, and a marked susceptibility to blockages, for instance due to buildings, foliage, and other obstacles, which can cause significant attenuation or even complete loss of signal~\cite{han2018propagation, jornet2011channel}.
5G introduced the preliminary support for \gls{mmwave} bands communications, partly overcoming these issues thanks to the use of \gls{mimo} arrays, beamforming, ad hoc control procedures~\cite{heng2021six}, and denser urban deployments~\cite{polese2020toward}.
Nevertheless, the unfavorable propagation characteristics exhibited by FR2 and above frequencies pose a significant challenge to the successful deployment of THz- and mmWave-based 6G wireless systems, especially since network densification is particularly costly for network operators~\cite{lopez2015towards}.

To extend the limited coverage of mmWave and THz deployments, the 3GPP approved, as part of its 5G NR specifications for Rel-16~\cite{3gpp_38_874}, \gls{iab} as a new paradigm to replace fiber-like infrastructures with self-configuring relays operating through wireless backhaul links.
Previous research has demonstrated that \gls{iab} systems represent a cost-performance trade-off~\cite{polese2020integrated}, since base stations need to multiplex access and backhaul resources, and wireless backhaul at mmWave frequencies are less reliable compared to their fiber counterpart.
Furthermore, if the partitioning of these spectrum resources is not optimally configured, IAB networks can experience excessive buffering, which in turn leads to increased latency and reduced throughput~\cite{8514996}. Finally, while lower than that of wired backhaul deployments, the \gls{capex} costs of \gls{iab} installation may still prove prohibitive for \glspl{mno}~\cite{chaoub20216g}.
In light of these limitations, new technologies such as \glspl{irs} and \gls{af} relays are also emerging as promising alternatives to overcome the coverage issues of mmWave networks with energy and cost efficiency in mind.
An \gls{irs} is a meta-surface whose elements can be programmed to manipulate electromagnetic fields in favor of a specific destination~\cite{wu2021intelligent}. By passively beamforming incoming signals without amplification, \glspl{irs} can meet the minimum capacity requirements in dead spots with reduced power consumption compared to approaches such as IAB~\cite{bjornson2019intelligent}. In contrast, \gls{af} relays are designed to capture incident electromagnetic waves from a base station, amplify the received signal, and re-radiate it towards a targeted area to be served.
While IRSs offer advantages in terms of lower power consumption, AF relays have the potential to achieve higher capacity by actively amplifying signals. However, similarly to IAB, this comes at the cost of increased complexity, higher system costs, and potential amplification noise issues~\cite{huang2019reconfigurable}.
Therefore, ubiquitous connectivity will only be achieved by integrating \glspl{ntn} within the depicted 6G wireless ecosystem, reaping their capability to deliver services anywhere and anytime~\cite{8766143}. In fact, the 3GPP is working on supporting the transparent integration of satellite gateways in the \gls{ran}~\cite{38821}, thus providing coverage to handheld devices in areas that are unreachable by conventional terrestrial deployment.

Whether these technologies will be able to fulfill future mobile service requirements and, if so, how they can be optimally integrated in 5G and 6G systems, are still crucial issues that remain unsolved. 
Indeed, for the next generation of cellular networks to fully achieve the ubiquitous goal, the above innovative deployment solutions will need to be properly evaluated and optimized in an iterative research cycle. To this end, it is of paramount importance to characterize the impact of these solutions on the end-to-end systems, i.e., from the signal propagation to the \gls{qoe} perceived by the end users, and in a reproducible manner.
However, performing accurate performance evaluations of disruptive deployment solutions on real-word testbeds is typically impractical, especially at scale, due to unavailability of suitable platforms and/or excessive deployment costs.
While these limitations are partly being addressed with initiatives such as the US-based \gls{pawr}~\cite{BONATI2023109502}, and the European IMAGINE-B5G~\cite{10597052} and 6G-SANDBOX~\cite{10597112} projects, which promote the development of emulation platforms to enable the controlled experimentation of cellular technologies, system-level simulators can still play a key role in wireless research.
In particular, system-level simulators can provide a playground for preliminary experimentation, at a scale which makes it unfeasible to perform network emulation, and or encompassing technologies for which hardware prototypes are not yet available. 
These advantages render simulators also well-suited to the study of \gls{ai} management and orchestration algorithms~\cite{polese2022colo}.
Indeed, in these contexts the training data must accurately capture the interplay of the whole protocol stack with the wireless channel. Furthermore, optimization frameworks such as \gls{drl} also call for preliminary testing in isolated yet realistic environments, with the goal of minimizing the performance degradation to actual network deployments~\cite{lacava2022programmable, amir2023safehaul}.
However, to fill these gaps, end-to-end network simulators must provide scalability to realistically-sized deployments, and a compelling performance-accuracy trade-off in their channel model offerings~\cite{testolina2020scalable}.

In this dissertation, besides providing a detailed overview of the aforementioned technologies, we advance the state of the art with improvements that span from the creation of simulation tools to the design of algorithms and protocols for innovative deployment solutions.
The presented work is the fruit of the collaboration with numerous researchers from world-leading universities, companies and research institutions, who played an important role in reaching these results. To properly acknowledge this collaborative effort, and the role of all the
authors involved, a comprehensive list of the publications produced throughout my Ph.D. (both accepted, under review and to be submitted) is reported at the end of this thesis. The latter is organized as follows.

Chapter~\ref{ch:sim-tools} provides on overview of the future role of network simulators in wireless research, and of the most promising key technology enablers for achieving ubiquitous mobile coverage in 6G. Then, we present novel simulation tools which enable the end-to-end simulation of 5G and 6G network deployments featuring innovative deployment solutions such as IRSs, AF relays and NTNs. Besides, we propose models for improving the computational efficiency of MIMO simulations, enabling the representation of massive cellular scenarios at scale.

Chapter~\ref{ch:iab} presents a semi-centralized resource partitioning scheme for 5G and beyond \gls{iab} networks, coupled with a set of allocation policies, and the first reliability-focused scheduling and path selection algorithm for \gls{iab} networks. Moreover, we provide a preliminary evaluation of the potential of mixed mmWave and THz self-backhauled networks.

Chapter~\ref{ch:irs-block} analyzes the performance of \gls{irs}-aided mobile network deployments with practical constraints on the \gls{irs} reconfiguration period. 
In this context, we propose a clustering-based scheduling algorithm which maximizes the system capacity by first grouping users with similar optimal \gls{irs} configurations, and then scheduling them jointly to reduce the number of IRS reconfigurations.
% We evaluate the efficacy of the proposed scheme in terms of computational complexity, sum capacity, and fairness across diverse channel conditions, and as a function of the \gls{irs} configuration and the number of users.

Finally, Chapter~\ref{ch:concl} concludes this thesis by summarizing its contributions and providing future research directions.