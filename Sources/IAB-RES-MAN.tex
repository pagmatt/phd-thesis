%%%%%%%%%%%%%%%
%%%   TWC %%%%%
%%%%%%%%%%%%%%%

\section{Semi-centralized framework for resource management in 5G NR Integrated Access and Backhaul}
\label{sec:iab-res-man}

%This section reviews relevant research on resources allocation in a multi-hop wireless network, deployed through either \gls{iab} or other wireless mesh solutions~\cite{gambiroza2004end}.

The literature adopts different approaches to model and solve the resource allocation problem in multi-hop wireless networks. 
The first, discussed in~\cite{qualcomm1, qualcomm2, kulkarni2018max, lei2020deep, rasekh2015interference, bilal2014time, cruz2003optimal} is based on conventional optimization techniques.
Specifically, the authors of~\cite{qualcomm1} present a simple and thus tractable system model and find the minimal number of \glspl{gnb} featuring a wired backhaul that are needed to sustain a given traffic load. Their work is further extended in~\cite{qualcomm2}, which provides an analysis of the performance benefits introduced by additional, fiber-less \glspl{gnb}. 
In~\cite{kulkarni2018max}, the mobile network is modeled as a noise-limited, $k$-ring deployment. Such model is then used to obtain closed-form expressions for the max-min rates achieved by \glspl{ue} in the network. Moreover,~\cite{lei2020deep} proposes a system model which leads to an NP-hard optimization problem, even though it considers single-hop backhaul networks only, and uses deep \gls{rl} to reduce its computation complexity. In~\cite{rasekh2015interference}, the joint routing and resource allocation problem is tackled via a \gls{lp} technique. Notably, this work assumes that data can be transmitted (received) toward (from) multiple nodes at the same time.
Similarly, the authors of~\cite{bilal2014time} formulate a \gls{tdd}, multi-hop resource allocation optimization problem which leverages the directionality of \gls{mmwave} antennas, albeit in the context of \gls{wpans}. Since such problem is also NP-hard, a sub-optimum solution is found. Finally,~\cite{cruz2003optimal} focuses on joint link scheduling, routing and power allocation in multi-hop wireless networks. As in previous cases the obtained optimization problem is not tractable: in this instance such obstacle is overcome by studying the dual problem via an iterative approach.

The second approach relies on stochastic geometry to model \gls{iab} networks~\cite{stoch_geom1, stoch_geom2}. Specifically,~\cite{stoch_geom1} determines the rate coverage probability of \gls{iab} networks and compares different access/backhaul resource partitioning strategies. Similarly,~\cite{stoch_geom2} provides a comparison of orthogonal and integrated resource allocation policies, although limited to single-hop wireless networks.  

Another significant body of literature leverages \glspl{mc} to study \gls{iab} networks; some of these works can be interpreted as a direct application of such theory~\cite{singh2018throughput, ji2012throughput}, while others~\cite{vu2018path,garcia2015analysis, gomez2016optimal, gomez2019optimal} exploit a more complex framework.  
The papers which belong to the former class are based on the  pioneering work of~\cite{tassiulas1990stability}, which inspects the stability of generic multi-hop wireless networks and formulates a throughput-maximizing algorithm known as \textit{back-pressure}. In particular,~\cite{singh2018throughput} focuses on the optimization of the timely-throughput, i.e., takes into account that packets usually have an arrival deadline. Such problem is then addressed by formulating a \gls{mdp}, leading to a distributed resource allocation algorithm. Similarly,~\cite{ji2012throughput} proposes an algorithm that also targets throughput optimality but, contrary to the back-pressure algorithm, manages to avoid the need for per-flow information.
On the other hand, the body of literature which belongs to the latter class uses the \gls{mc}-derived \gls{num} framework first introduced in~\cite{kelly1997charging} and ~\cite{kelly1998rate}. Specifically, the authors of~\cite{vu2018path} focus on satisfying the \gls{urllc} \gls{qos} requirements by jointly optimizing routing and resource allocation. Then, 
%the problem is decoupled into two successive phases, the first exploiting \gls{rl} for achieving an optimal routing and the latter employing convex optimization in order to solve the resource allocation problem%
the problem is solved using both convex optimization and \gls{rl} techniques. In~\cite{garcia2015analysis}, an in-depth analysis of a \gls{mmwave}, multi-hop wireless system is presented, proposing and comparing three different interference frameworks, under the assumption of a dynamic \gls{tdd} system. This work is extended in~\cite{gomez2016optimal} and~\cite{gomez2019optimal}, which consider respectively a \gls{sdma} and a \gls{mu}-\gls{mimo} capable system.

Finally, only a small portion of the literature~\cite{polese2018end, polese2018iab, polese2020integrated} analyzes the end-to-end performance of \gls{iab} networks. Specifically, the authors of~\cite{polese2018end} extend the ns-3 \gls{mmwave} module, introducing realistic \gls{iab} functionalities which are then used to characterize the benefit of deploying wireless relays in \gls{mmwave} networks. Their work is extended in~\cite{polese2018iab}, where path selection policies are formulated and their impact on the system performance is inspected. A further end-to-end analysis of \gls{iab} networks is carried out in~\cite{polese2020integrated}, providing insights into the potentials of this technology and the related open research challenges.

Concluding, the literature exhibits the presence of algorithms relying on a varying degree of assumptions on the network topology and the knowledge of system. Furthermore, most of the aforementioned studies lack an end-to-end, full-stack system-level analysis of the proposed solution.
To fill these gaps, this section proposes a semi-centralized resource allocation scheme which exhibits low complexity, both computationally and in terms of required feedback. Moreover, we provide considerations on how our proposed solution can be implemented and deployed in standard-compliant \gls{3gpp} \gls{iab} networks, and compare such solution to the state of the art with an end-to-end, realistic performance analysis

\subsection{Contributions}
\label{sec:contributions}

This remainder of this section tackles the access and backhaul partitioning problem by proposing an optimal, semi-centralized resource allocation scheme for \gls{3gpp} \gls{iab} networks, based on the \gls{mwm} problem on graphs. It receives periodic L1 and/or L3 measurements from the nodes of the \gls{iab} deployment, a possibility which is explicitly mentioned by 3GPP in~\cite[Section 7.3.3]{3gpp_38_874}, constructs a spanning tree that represents the deployment, and uses a simplified, low-complexity version of the \gls{mwm} to partition the links between access and backhaul. After a feedback step, each node can then schedule the resources at a subframe-level among the connected devices. 

To the best of our knowledge, this is the first \gls{mwm}-based resource allocation framework for \gls{3gpp} \gls{iab} networks at \glspl{mmwave}. As such, it exhibits the following benefits:
\begin{enumerate*}[label=(\roman*)]
  \item no constraints on the number of hops in the \gls{iab}-network are introduced, and, more in general, it is \gls{3gpp}-compliant;
  \item a globally optimum is computed;
  \item generic network utility functions can be used;
  \item it features a computational complexity which is linear in the number of \glspl{gnb} which are connected to the same \gls{iab}-donor; and 
  \item a very limited communication overhead is required.
\end{enumerate*}

In particular, the flexibility makes it possible to easily adapt the resource allocation strategy to different requirements, use cases, and classes of traffic for \gls{5g} networks. We achieve this by developing a generic optimization algorithm, which identifies with a configurable periodicity the access and backhaul partition that optimizes a certain utility function. The selection of the utility function prioritizes the optimization of different metrics, e.g., throughput or latency, which in turn can be mapped to different classes of traffic.

Moreover, to achieve the compliance with the \gls{3gpp} \gls{iab} specifications, the resource allocation framework relies only on information that can be actually exchanged and reported in a \gls{3gpp} deployment. In this regard, we also review the latest updates related to the \gls{3gpp} \gls{iab} standardization activities. Nevertheless, our solution can be easily extended to consider other types of feedback information.
Finally, the algorithm operates with a low complexity, i.e., we propose a version of the \gls{mwm} algorithm that can be applied on spanning trees with linear complexity in the number of nodes in the network infrastructure, and demonstrate its equivalence to the generic (and more complex) \gls{mwm}. Additionally, the proposed framework also relies on a feedback exchange that is linear in the number of base stations, and is thus decoupled from the number of users. Along this line, the semi-centralized nature of the proposed solution combines the benefit of a centralized point of view for the allocation of inter-dependent \gls{iab} links and a limited complexity.

Furthermore, we evaluate the performance of the proposed scheme with an end-to-end, full-stack system-level simulation, using the ns-3 mmWave module~\cite{mezzavilla2018end} and its \gls{iab} extension~\cite{polese2018end}. This represents the first evaluation of an optimized resource allocation scheme for \gls{iab} with a simulator that is based on a \gls{3gpp}-compliant protocol stack, uses \gls{3gpp} channel models, and integrates realistic applications and transport protocols. The extended performance evaluation highlights how the proposed scheme improves the throughput of a diverse set of applications, with a 5-fold increase for the worst case users, with different packet sizes and transport protocols, while decreasing the latency and buffering at intermediate nodes by up to 25 times for the smallest packet sizes.

The remainder of this section is organized as follows. Section~\ref{Sec:Sys-model} describes our assumptions and the system model. Then, Section~\ref{Sec:scheme_main} presents a novel scheme for resource partitioning in \gls{mmwave} \gls{iab} networks, along with considerations on how it can be implemented in \gls{3gpp} NR. Finally, Section~\ref{Sec:perf_eval} describes the performance evaluation results.

%TODO Is it a proper name?
\subsection{IAB networks}
\label{Sec:Sys-model}

%TODO Add, somewhere, a more in-depth introduction on IAB (what is a donor, what is a node, ecc.)
The following paragraphs identify the characteristics and constraints of \gls{mmwave} \gls{iab}, according to the \gls{3gpp} design guidelines presented in~\cite{3gpp_38_874} and the specifications of~\cite{3gpp_38_174}.

\subsubsection{Network topology}
In general, an \gls{iab} network is a deployment where a percentage of \glspl{gnb} (i.e., the \gls{iab}-nodes) use wireless backhaul connections to connect to a few \glspl{gnb} (i.e., the \gls{iab}-donors) which feature a wired connection to the core network, as can be seen in Fig.~\ref{Fig:IAB_top_not}.
Moreover, these deployments exhibit a \textit{multi-hop} topology where a strict parent-child relation is present. The former can be represented by the \gls{iab}-donor itself or an \gls{iab}-node; the latter by either \gls{ue}s or downstream \gls{iab}-nodes. In~\cite{3gpp_38_874}, no a priori limit on the number of backhaul hops is introduced. As a consequence, \gls{3gpp} argues that \gls{iab} protocols should provide sufficient flexibility with respect to the number of backhaul hops. 
Moreover, the \gls{si} on \gls{iab}~\cite{3gpp_38_874} highlights the support for both the topologies depicted in Fig.~\ref{Fig:IAB_topology}, i.e., \gls{st} and \gls{dag} \gls{iab}. Clearly, the former exhibits less complexity but, at the same time, poses some limits in terms of network performance: the possible presence of obstacles may result in a service interruption, due to the unique backhaul route established by the \glspl{ue}. 
On the other hand, a \gls{dag} topology offers routing redundancy, which can be used not only to decrease the probability of experiencing a ``topological blockage," but also for load balancing purposes.

%\begin{figure}[h!]
%\captionsetup{singlelinecheck=false, justification=justified}
%\centering
%\includegraphics[width=0.7\linewidth]{IAB_Topology.pdf}
%\caption{\gls{iab}-network topologies analyzed in~\cite{3gpp_38_874}.}
%\label{Fig:IAB_topology}
%\end{figure}

%More details on such regard are given in Section~\ref{Subsec:sys_model}.

\subsubsection{Multiple access schemes and scheduling}
An in-band, dynamic partitioning of the access and backhaul spectrum resources is currently preferred by \gls{3gpp}~\cite{3gpp_38_874, 3gpp_38_174}, together with half-duplex operations of the \gls{iab}-nodes. Moreover, most of the literature suggests that \gls{5g} \gls{mmwave} systems will operate in a \gls{tdd} fashion~\cite{khan2011mmwave, dutta2017frame}. This choice is mainly driven by the stringent latency requirements which the next generation of mobile networks will be required to support, and by the usage of analog or hybrid beamforming. The usage of \gls{fdd}, in conjunction with the presence of large chunks of bandwidth, would lead to severe resource under-utilization and make channel estimation more difficult.
Based on these considerations, the system model exhibits a \gls{tdd}, \gls{tdma}-based scheduling where the access/backhaul interfaces are multiplexed in a half-duplex manner. 
Coupled with \glspl{mmwave} directionality, this means that self and inter-cell-interference are both limited, as reported by~\cite{qualcomm1}.
Furthermore, at any given time instant, each node of the \gls{iab} network cannot be simultaneously involved in more than one transmission or reception. In particular, \gls{iab}-nodes cannot schedule time and frequency resources which are already allocated by their parent for backhaul communications which involve them.
Moreover, the backhaul links of a given \gls{gnb} might also carry data which is destined to (and/or generated by) \glspl{ue} which are connected to different base stations. 
As a consequence, an \gls{iab}-network exhibits a marked and peculiar inter-dependence between the resource allocations of the various base stations, which is the major motivation for the introduction of a semi-centralized framework. 

\begin{figure}[tbp]
	\centering
	%\captionsetup{singlelinecheck=false, justification=justified}
  % this sets the width of the figure, adjust to your needs
  	\subfloat[\gls{st} and \gls{dag} topologies.\label{Fig:IAB_topology}]{
  	\includegraphics[width=0.55\columnwidth]{Figures/CentralResourceManagement/IAB_Topology.pdf}}\hfill
  	\subfloat[System model notation.\label{Fig:IAB_notation}]{
  	\includegraphics[width=0.55\columnwidth]{Figures/CentralResourceManagement/IAB_Notation.pdf}}
    \caption{Comparison of the \gls{iab} network topologies analyzed in~\cite{3gpp_38_874} and related notation.}
    \label{Fig:IAB_top_not}
    % \vspace{-.6cm}  
\end{figure}

%TODO Explain scheduling and better formulation of the half-duplex explanation(e.g. the backhaul-aware)
Finally, the introduction of resource coordination mechanisms and related signaling is explicitly supported in the \gls{iab} specification drafts~\cite{3gpp_38_874, 3gpp_38_174}. Nevertheless, these solutions must reuse as much as possible the available NR specifications and
require at most minimal changes to the Rel.15 \gls{5gc} and \gls{nr}.

%According to these considerations, the remainder of this section will propose a generic algorithm for centralized access/backhaul resource partitioning which aims to be scalable, efficient and, in general, implementable in real-world deployments.

\subsubsection{System model}
\label{Subsec:sys_model}

According to these assumptions and referring to Fig.~\ref{Fig:IAB_notation}., a generic \gls{iab} network can be modeled as a directed graph $\mathcal{G} = \{\mathcal{N},  \mathcal{E} \}$, where the set of nodes $\mathcal{N} \mathop = \limits^{\Delta} \, \{ n_1, \, n_2, \, \ldots \, n_{\vert \mathcal{N} \vert }  \}$ comprises the \gls{iab}-donor, the various \gls{iab}-nodes and the \glspl{ue}. 
Accordingly, the set of directed edges $\mathcal{E} \mathop = \limits^{\Delta} \, \{ e_{1} , \, e_{2}, \, \ldots \, \allowbreak e_{\vert \mathcal{E} \vert} \} \equiv \{ e_{n_j \to n_k} \}_{j, k} $, where the edge $e_{n_j \to n_k}$ originates at the parent node $n_j$ and terminates at the children $n_k$, comprises in all the active cell attachments, either of mobile terminals to a \gls{gnb} or from \gls{iab}-nodes towards their parent node.
Since the goal of this section is to study backhaul/access resource partitioning policies, this generic model can be actually simplified: in fact, all the \glspl{ue} connected to a given \gls{gnb} can be represented by a single node in $\mathcal{G}$ without any loss of generality. Similarly, the same holds true for their links toward the serving \gls{gnb}, which can then be represented by a single edge. 
%TODO Maybe mention that as a consequence the number of edges is significantly reduced, taking into consideration the expected # of UEs connected to a BS in 5G systems
Furthermore, this work focuses on \gls{st} topologies only. 

We define as \textit{feasible schedule} any set of links $\mathcal{E'} \subseteq \mathcal{E}$ such that none of them share a common vertex, i.e., $ \forall \, e_{n_j \to n_k} \neq e_{n_l \to n_m} \in \mathcal{E'}$ it holds that $n_{j} \neq n_{m}$ and $n_{l} \neq n_{k}$. Let then $f_u$ be a utility \textit{additive map}, namely, a function such that the overall utility experienced by the system when scheduling edges $e_1$ and $e_2$ satisfies $f_u (e_1, e_2) = f_u (e_1) + f_u(e_2)$. Let also $\mathcal{W} \mathop = \limits^{\Delta} \, \{ w_1, \, w_2, \, \ldots \, w_{\vert \mathcal{E} \vert } \}$ be the set of positive weights whose generic entry $w_j$ represents the utility which is obtained when scheduling the $j$-th edge, namely, $w_j \mathop = \limits^{\Delta} \, f_u (e_j)$. Then, the overall utility of the system is $\mathcal{U} \mathop = \limits^{\Delta} \, \sum_{e_k \, \in \, \mathcal{E'}} f_u(e_k) = \sum_{e_k \, \in \, \mathcal{E'}} w_k $.
The goal is to find the feasible set $\mathcal{E'}^{*}$ which maximizes the overall utility, i.e., $\underset{\mathcal{E'}}{\mathrm{argmax}} \,\, \mathcal{U} $. In computer science, this task is typically referred to as the \textit{Maximum Weighted Matching} problem~\cite{Korte2002}.

Finding the \gls{mwm} of a given graph, in the general case, is not trivial from a computational point of view. 
In fact, the fastest known \gls{mwm} algorithm for generic graphs has a complexity of \bigO{\vert V \vert \vert E \vert + \vert V \vert^2 \log{\vert V \vert}}~\cite{1990Gabow}, posing serious limitations to the suitability of such algorithm to \gls{5g} and beyond networks, which target a connection density of 1 million devices per km\textsuperscript{2}. However, we argue that under the aforementioned assumptions on the system model, which restrict the network to an \gls{st} topology, it is possible to design an \gls{mwm}-based semi-centralized resource partitioning framework which exhibits linear complexity with respect to the network size and which, as a result, is able to satisfy the scalability requirements highlighted by \gls{3gpp} in~\cite{3gpp_38_874}. 
Nevertheless, the proposed framework can be easily extended to the case of a \gls{dag} \gls{iab} network. In such regard, a sub-optimal strategy is to periodically discard, during each centralized allocation, the redundant edges of each node. In such a way, the input which is fed to the \texttt{T-MWM} algorithm is, effectively, an \gls{st}. A second, optimal extension can be obtained by computing at the controller the \gls{mwm} of the network via a generic \gls{mwm} algorithm, instead of using the \gls{st}-specific \texttt{T-MWM} as in the proposed framework. However, this strategy would feature a higher computational complexity.

\subsection{Semi-centralized resource allocation scheme for IAB networks}
\label{Sec:scheme_main}

This section presents an \gls{mwm} algorithm for \gls{st} topologies (Section~\ref{Sec:T-MWM}), an efficient and \gls{mwm}-based semi-centralized resource partitioning framework for \gls{iab} networks (Section~\ref{Sec:Cent-scheme}) and some considerations about its implementation (Section~\ref{Sec:ns3-impl}). 
Specifically, the proposed scheme collects at a controller installed on the \gls{iab}-donor L1 and/or L3 measurements from the various \glspl{gnb}. Then, it uses such information to build a weighted \gls{st} which represents the \gls{iab}-network. In particular, the network topology is inferred by examining the incoming parent-child associations. The edge weights are also computed from the received measurements, based on the specific policy (hence, of target \glspl{kpi}) of choice. Finally, the resource partitioning is optimized by computing an \gls{mwm} of the network and then prioritizing the links which comprise it. A high level diagram of is provided in Fig.~\ref{Fig:Diagram}.

\begin{figure}[tbp]
    \subfloat[IAB protocol stack and topology.\label{Fig:IAB-net}]{
    \includegraphics[width=0.95\linewidth]{Figures/CentralResourceManagement/architecture_full.png}}\hfill
    \subfloat[High level diagram of the proposed \gls{mwm}-based framework.\label{Fig:Diagram}]{
    \includegraphics[width=0.95\linewidth]{Figures/CentralResourceManagement/FlowChart_IAB.png}}
    \caption{IAB topology and proposed MWM-based framework.}
    \label{fig:fr-top}
\end{figure}

\subsubsection{MWM for ST graphs}
\label{Sec:T-MWM}

As the first of our contributions, we present an algorithm, hereby called \texttt{T-MWM}, which computes the \gls{mwm} of an \gls{st} in linear time. In particular, \texttt{T-MWM} is a bottom-up algorithm which, upon receiving as input a weighted \gls{st} $\mathcal{G}$ described by its edge map $\mathbf{E}$ and the corresponding weight map $\mathbf{W}$, produces as output a set of active edges $\mathbf{E^*}$ which are an \gls{mwm} of $\mathcal{G}$. That is to say, $\mathbf{E^*}$ is a matching of $\mathcal{G}$ which yields the globally maximum utility.
Furthermore, $\mathbf{E}$ is from now on assumed to exhibit the following invariant: each \gls{iab} parent precedes its children in the map, hence avoiding the need for a recursion. 
%TODO can remove this when we add the discussion on the complexity of each phase
This is automatically obtained as each \gls{iab} child connects after its parent, and is thus added to the map in a subsequent position.
Nevertheless, this assumption can be easily relaxed, albeit at the cost of losing as a side-effect the bottom-up design.

%TODO rewrite, do not include what used to be Lemma 1.
% Needs a link between these two sections

The proposed algorithm is designed starting from the observation that, given the generic node $n_k \in \mathcal{G}$ and a matching $\mathbf{\bar{E}}$ of $\mathcal{G}$, we can identify the following mutually exclusive and collectively exhaustive cases: $\mathbf{\bar{E}}$ can contain either one or zero edges which originate from $n_k$. Based on this fact, we then discern the optimal utilities which can be obtained in each of these cases. Specifically, we define the maximum utilities yielded by a matching of $n_k$'s sub-tree which either contains a link originating from $n_k$ or not as $\mathbf{F}(n_k)$ and $\mathbf{G}(n_k)$, respectively.
Then, as can be seen in Alg.~\ref{Alg:tmwm}, the \texttt{T-MWM} algorithm basically consists in two traversals of the network graph. During the first one we compute the $\mathbf{G}$ and $\mathbf{F}$ functions for all the nodes in $\mathcal{G}$ using the recursive formulas provided by Lemma~\ref{lemma_utils}. Finally, during the second traversal, this knowledge is used for computing an \gls{mwm} of the network; the correctness of this last phase is proved by Lemma~\ref{lemma_active_edges}.

%Specifically, these formulas are based on the following observations.
%First, given the generic internal node $n \in \mathcal{G}$, any \gls{mwm} contains an edge which originates either from $n$ or one of its children, as stated in Lemma~\ref{lemma_ch_par}. It follows that if the \gls{mwm} does not contain any edge which originates from $n$, the maximum utility is achieved when activating \textit{all} the edges which originate from its children. On the other hand, whenever the edge from $n$ to its generic child $m$ is included in the \gls{mwm}, the
%All together, these first two Lemmas prove the correctness of the first part of Alg.~\ref{Alg:tmwm}.

%TODO Maybe rework edges notation here as well, in order to make it slightly more uniform
\begin{algorithm}[tbp!]
\small
    \caption{Tree-Maximum Weighted Matching}
    \label{Alg:tmwm}
    \hspace*{\algorithmicindent} \textbf{Input:} A weighted \gls{st} $\mathcal{G}$ encoded by a map $\mathbf{E}$, which associates each node in $\mathcal{G}$ to its edges, and the corresponding weights map $\mathbf{W}$. \\ 
    \hspace*{\algorithmicindent} \textbf{Output:} An \gls{mwm} $\mathbf{E^*}$ of $\mathcal{G}$. 
    \begin{algorithmic}[1] % The number tells where the line numbering should start
        \Procedure{\texttt{T-MWM}}{$\mathbf{E}, \mathbf{W}$} 
            \State $\mathbf{F} \gets \mathbf{0}$; $\mathbf{G} \gets \mathbf{0}$ \Comment{Initialize the utility vectors to zero vectors}
            \State $\mathbf{E^*} \gets \{ \}$ \Comment{Initialize the set of active edges as empty}
            \For{each internal node $n_k \in \mathbf{E}$} \Comment{\parbox[t]{.43\linewidth}{In ascending order w.r.t. to their depth in $\mathcal{G}$}}
            \State $maxUtil \gets - \infty$;  $\mathbf{maxUtilChild}(n_k) \gets \{ \}$
            \For{each edge $e_{n_k \to n_j} \in \mathbf{E}(n_k) $} \Comment{Iterate over its edges}
                \State $\mathbf{G}(n_k) \gets \mathbf{G}(n_k) + \max \left\{ \mathbf{F}(n_j), \mathbf{G}(n_j) \right\}$
                \State $currUtil \gets \mathbf{W} ( e_{n_k \to n_j} ) - \left[ \mathbf{F}(n_j) - \mathbf{G}(n_j) \right]^+  $
            \If{$currUtil > maxUtil$}
            	\State $maxUtil \gets currUtil$;  $\mathbf{maxUtilChild}(n_k) \gets n_j$ 
            \EndIf
            \EndFor\label{edgesFor}
            \State $\mathbf{F}(n_k) \gets \mathbf{G}(n_k) + maxUtil$ 
            \EndFor\label{nodesFor}
			
			\For{each internal node $n_k \in \mathbf{E}$} \Comment{\parbox[t]{.43\linewidth}{In ascending order w.r.t. to their depth in $\mathcal{G}$}}			
			
				\If { $\mathbf{F}(n_k) \geq \mathbf{G}(n_k)$}
					\State $\mathbf{E^*} \gets \mathbf{E^*} \cup e_{n_k \to \mathbf{maxUtilChild}(n_k)}$
					\State $\mathbf{F}(\mathbf{maxUtilChild}(n_k)) \gets -\infty$ \Comment{\parbox[t]{.3\linewidth}{Ensure child does not get activated multiple times}}
				\EndIf\label{activeIf}
			\EndFor\label{edgesFor2}            
            
            \State \textbf{return} $\mathbf{E^*}$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

%\begin{lem}
%\label{lemma_ch_par}
%Let $n_k$ be an arbitrary internal node of $\mathcal{G}$ and $\{ n_j \}_k$ be the set of its children. Then, any \gls{mwm} of $\mathcal{G}$ must contain an edge which has as one of its vertices either $n_k$ or an element of  $\{ n_j \}_k$.
%\end{lem}
%
%\begin{IEEEproof}
%Suppose there exists an \gls{mwm} $\mathbf{E^*}$ of $\mathcal{G}$ which does not contain any such edge. Then the set $\hat{\mathbf{E}}^* \mathop = \limits^{\Delta} \, \mathbf{E^*} \cup \{ e_{n_k \to n_m} \}$, where $ e_{n_k \to n_m} $ is the edge from $n_j$ to its (arbitrary) child $n_m$ is still a feasible activation set, since no edge in $\mathbf{E^*}$ shares such vertices. Furthermore, since the weights are positive we have that $f_u (\hat{\mathbf{E}}^*) = f_u (\mathbf{E^*}) + \mathbf{W} (e_{n_k \to n_m}) > f_u (\mathbf{E^*}) $, which is clearly a contradiction.
%\end{IEEEproof}

\begin{lem}
\label{lemma_utils}
Given an \gls{st} $\mathcal{G}$, consider its generic internal node $n_k$. Let then $\mathbf{F}(n_k)$ be the maximum utility yielded by a matching of $n_k$'s sub-tree which activates a link originating from $n_k$, and $\mathbf{G}(n_k)$, conversely, the utility provided when such matching contains no links which feature $n_k$ as parent. Then, we have that:
\[ 
\begin{cases}
\mathbf{G}(n_k) = \sum\limits_{ \{ n_j \}_k} \max \left\{ \mathbf{F}(n_j), \mathbf{G}(n_j) \right\} \\

\begin{aligned}
\mathbf{F}(n_k) &= \mathbf{G}(n_k) + \underset{\{ n_j \}_k }{\max} \{ \mathbf{W} ( e_{n_k \to n_j} ) \\
&- \left[ \mathbf{F}(n_j) - \mathbf{G}(n_j) \right]^+ \}
\end{aligned}


\end{cases}
\]
where the set $\{ n_j \}_k$ comprises all the children of $n_k$ and $\left[ x \right]^+ = \max\{x, 0\}$ is the positive part of $x$.
%
Conversely, for leaf nodes $n_l$ it holds that $\mathbf{F}(n_l) \equiv \mathbf{G}(n_l) \equiv 0 $.
\end{lem}

\begin{proof}
This lemma can be proved by induction over the height $h_k$ of the sub-tree corresponding to node $n_k$. The base case is $h_k = 0$, i.e., when $n_k$ is a leaf node; in this case, trivially, both $\mathbf{F}(n_k)$ and $\mathbf{G}(n_k)$ are zero since no links exhibit $n_k$ as parent node and the sub-tree of $\mathcal{G}$ which originates in $n_k$ consists of $n_k$ only, respectively.

Then, assume that $n_k$'s sub-tree exhibits a generic height $h_k > 0$, and that the above formulas hold for each of its children sub-trees, which exhibit a height $h_j < h_k$. If we do not activate any edge which originates from $n_k$, then no added constraints are introduced concerning the edges which can be activated in its children sub-trees. Therefore, %the maximum utility achieved by any matching of $n_k$'s sub-tree, without activating any node which originates from $n_k$, 
$\mathbf{G}(n_k)$ is simply the sum of the utilities achieved by any \gls{mwm} computed on its children sub-trees, i.e.,  $\mathbf{G}(n_k) = \sum\limits_{ \{ n_j \}_k} \max \left\{ \mathbf{F}(n_j), \mathbf{G}(n_j) \right\}$.
The remaining option is to activate exactly one edge, hereby called $e_{n_k \to n_m}$, which originates from $n_k$. In this case, no additional edges which feature $n_m$ as parent can be added to the matching. As a consequence, the contribution of $n_m$'s sub-tree on $\mathbf{F}(n_k)$ reads $\mathbf{G}(n_m)$. Conversely, no additional constraints are introduced regarding the other nodes. It follows that the utility obtained in this instance reads:
\[ \sum_{ \{ n_j \neq n_m\}_k } \max \left\{ \mathbf{F}(n_j), \mathbf{G}(n_j) \right\} +  \mathbf{W} ( e_{n_k \to n_m} ) + \mathbf{G}(n_m) \]
and can be rewritten as:
\[  \mathbf{G}(n_k) + \mathbf{W} ( e_{n_k \to n_m} ) - \left[ \mathbf{F}(n_m) - \mathbf{G}(n_m) \right]^+ \]
Finally, such utility is clearly maximized when $n_m$ is chosen as $ \underset{ \{ n_j \}_k }{\mathrm{argmax}} \, \{ \mathbf{W} ( e_{n_k \to n_j} ) - \left[ \mathbf{F}(n_j) - \mathbf{G}(n_j) \right]^+ \}$, yielding:
\[ \mathbf{F}(n_k) = \mathbf{G}(n_k) + \underset{\{ n_j \}_k }{\max} \, \{ \mathbf{W} ( e_{n_k \to n_j} ) - \left[ \mathbf{F}(n_j) -  \mathbf{G}(n_j) \right]^+ \} \qedhere \] 
\end{proof}

\begin{lem}
\label{lemma_active_edges}
Given an \gls{st} $\mathcal{G}$ of root $n_r$ and the $\mathbf{F}$ and $\mathbf{G}$ functions computed as per Lemma~\ref{lemma_utils}, an \gls{mwm} $\mathbf{E^*}$ of $\mathcal{G}$ can be computed by performing the following procedure:
%, in a recursive fashion
\begin{enumerate}
\item If $ \, \mathbf{F}(n_r) \geq \mathbf{G}(n_r) $, add to $\mathbf{E^*}$ the edge from $n_r$ to $n_m$, where the latter is defined as $n_m \mathop = \limits^{\Delta} \, \underset{ \{ n_j \}_r }{\mathrm{argmax}} \, \{ \mathbf{W} ( e_{n_r \to n_j} ) - \left[ \mathbf{F}(n_j) - \mathbf{G}(n_j) \right]^+ \}$. Then, repeat recursively on all the sub-trees corresponding to $n_r$'s children $\{ n_j\}_r \, \vert \, n_j \neq n_m$ and on the children of $n_m$ itself.
\item If $ \, \mathbf{F}(n_r) < \mathbf{G}(n_r) $, repeat recursively on all the sub-trees corresponding to $n_r$'s children.
\end{enumerate}
\end{lem}

%TODO Add more details
\begin{proof}
The above procedure always yields a feasible activation, i.e., a matching of $\mathcal{G}$.  In particular, in either options we never recurse on a node which has already been activated, hence no pair of edges $\in \mathbf{E^*}$ can share any vertices. Furthermore, due to the properties of $\mathbf{F}$ and $\mathbf{G}$, whenever $\mathbf{F}(n_r) \geq \mathbf{G}(n_r)$ a matching yielding maximal utility can be obtained by activating the edge $e_{ n_r \to n_m }$, where $n_m \mathop = \limits^{\Delta} \, \underset{ \{ n_j \}_r }{\mathrm{argmax}} \, \{ \mathbf{W} ( e_{n_r \to n_j} ) - \left[ \mathbf{F}(n_j) - \mathbf{G}(n_j) \right]^+ \}$.
Since the procedure is then recursively repeated on $n_r$'s children and the validity of $\mathbf{F}$ and $\mathbf{G}$ properties holds for each sub-tree in $\mathcal{G}$, the set of edges $\mathbf{E^*}$ produced by the above procedure comprise a \textit{maximal} matching, i.e., they yield the maximum possible utility among all the feasible schedules. 
\end{proof}

%TODO consider moving this paragraph to the framework steps, together with the complexity and overhead considerations provided in the review for all the framework steps
Regarding the computational complexity of the proposed algorithm, it can be observed that during the first phase the main loop effectively scans each edge of $\mathcal{G}$, hence exhibiting a complexity \bigO{\vert \mathbf{E} \vert}. Moreover,
the second phase of \texttt{T-MWM} has complexity \bigO{\vert \mathbf{V} \vert}, since it loops through all the network nodes.
Therefore, we can conclude that the overall asymptotic complexity of the algorithm is \bigO{\vert \mathbf{V} \vert + \vert \mathbf{E} \vert}, or, equivalently, \bigO{\vert \mathbf{V} \vert} since in an \gls{st} the number of edges equals $\vert \mathbf{V} \vert - 1$.

\subsection{Semi-centralized resource partitioning scheme}
\label{Sec:Cent-scheme}
Based on the system model introduced in Section~\ref{Sec:Sys-model}, and the \texttt{T-MWM} algorithm, we present a generic optimization framework which partially centralizes the backhaul/access resource partitioning process, in compliance with the guidelines of~\cite{3gpp_38_874}. 
The goal of this framework is to aid the distributed schedulers, adapting the number of \gls{ofdm} symbols allocated to the backhaul and access interfaces to the phenomena which exhibit a sufficiently slow evolution over time, i.e., large scale fading and local congestion. % Maybe mention also effectiveness of centralized is exarcebated by TDD constraints
This optimization is undertaken with respect to a generic additive utility function $f_u$. An \gls{iab} network of arbitrary size is considered, composed of a single \gls{iab}-donor, multiple \gls{iab}-nodes and a (possibly time-varying) number of \glspl{ue} which connect to both types of \glspl{gnb}. %TODO Ask Tommaso/Michele 
%The choice of neglecting cooperation among neighboring sectors is motivated by the fact that different \gls{iab}-donors are likely to be separated by a distance which is significantly greater than their respective coverage area (in fact, if this would not be the case, there would not be the need for \gls{iab} in the first place). % Not impossible, but arguably sub-optimal
%Therefore, we deem an inter \gls{iab}-donors resource coordination to be an unrealistic scenario, which as a consequence is out of the scope of this paper.
%TODO But wired info exchange is actually possible (X2), needs further work or remove entirely 
Furthermore, %let the topology of the \gls{iab} network be pre-computed, for instance by using the policies of~\cite{polese2018iab}, and 
assume that a central controller is installed on the \gls{iab}-donor. 

The proposed framework can be subdivided into the following phases, which are periodically repeated every $T_{alloc}$ subframes:
\begin{enumerate}
\item \label{Enum_frameword:item_one} \textbf{Initial setup}. This step, which is depicted in Fig.~\ref{Fig:Phase0}, consists in the computation of the simplified \gls{iab} network graph $\mathcal{G} \equiv \{ \mathcal{V}, \mathcal{E} \}$. Specifically, after this phase $\mathcal{V}$ comprises the donor and the various \gls{iab}-nodes. Accordingly, $\mathcal{E}$ contains their active cell associations.

\item \label{Enum_frameword:item_two} \textbf{Information collection}. During this phase, the various \gls{iab}-nodes send to the central controller a pre-established set of information for each of their children in $\mathcal{G}$. For instance, this feedback may consist in their congestion status and/or  information regarding their channel quality. To such end, the implementation presented in this section uses modified versions of pre-existing \gls{nr} Release 16 \glspl{ce}, as strongly recommended in the \gls{iab} SI~\cite{3gpp_38_874}. However, the scheme does not actually impose any limitations in such regard.
\item \label{Enum_frameword:item_three} \textbf{Centralized scheduling indication}. Upon reception of the feedback information, the central controller updates $\mathcal{G}$ by inspecting the received node-parent associations. Then, the set of weights $\mathcal{W}$ is calculated and an \gls{mwm} of $\mathcal{G}$ is computed, using the \texttt{T-MWM} algorithm. The output of this procedure is the activation set $\mathbf{E^*}$, which yields a globally optimum solution with respect to the chosen utility function. Subsequently, $\mathbf{E^*}$ is used as to create a set of \textit{favored} downstream nodes, i.e., of children which will be served with the highest priority by their parent, as depicted in Fig.~\ref{Fig:Phase2}. Finally, these scheduling indications are forwarded to the various \gls{iab}-nodes which act as parents in the edges of $\mathbf{E^*}$.

\begin{figure}[tbp]
	\centering
	%\captionsetup{singlelinecheck=false, justification=justified}
  % this sets the width of the figure, adjust to your needs
  	\subfloat[The original topology, exhibiting the actual cell attachments, is depicted on the left. Conversely, the reduced one is shown on the right.\label{Fig:Phase0}]{
  	\includegraphics[width=0.7\linewidth]{Figures/CentralResourceManagement/Phase0.png}
    }\hfill
  	\subfloat[Computation of the \gls{mwm} and of the corresponding scheduling indications.\label{Fig:Phase2}]{
  	\includegraphics[width=0.7\linewidth]{Figures/CentralResourceManagement/Phase2.png}
    }
    \caption{High level scheme of the initial setup and centralized scheduling indication phases.}
    \label{Fig:Phases}
    %\vspace{-.6cm}  
\end{figure}


\item \textbf{Distributed scheduling allocation}. During this phase, the various \gls{iab}-nodes make use of the indications received by the central controller, if available, in order to perform the actual scheduling (which is, therefore, predominantly distributed). Specifically, the favored nodes are served with the highest priority, while the remaining downstream nodes are scheduled if and only if the resource allocation of the former does not exhaust the available \gls{ofdm} symbols.
\end{enumerate}
It is important to note that since $\mathcal{G}$ contains only the \gls{iab}-nodes, the donor and at most one ``representative" \gls{ue} per \gls{gnb}, the proposed scheme effectively performs only the backhaul/access resource partitioning in a centralized manner. On the other hand, the actual \gls{mac}-level scheduling is still undertaken in a distributed fashion, albeit leveraging the indications produced by the central controller. The major advantages which this two-tier design exhibits, compared to a completely centralized solution, are the presence of a relatively light signaling overhead and the ability to promptly react to fast channel variations, for instance caused by small scale fading.  

\subsection{Implementation of semi-centralized allocation schemes in mmWave IAB networks}
\label{Sec:ns3-impl}

The remainder of this section discusses how the proposed scheme can be implemented in \gls{iab} deployments, with references to how the \gls{3gpp} specifications can support it. Moreover, an in-depth analysis of the framework's communication overhead and computational complexity is provided. To such end, let $\mathcal{G} = \{ V, E \}$ be the reduced network graph, computed as per Section~II-C, and, conversely, let $\mathcal{\bar{G}} = \{ \bar{V}, \bar{E} \}$ comprise all the nodes in the \gls{iab} network.
% presents an implementation of the proposed scheme in the network simulator ns-3, along with considerations on its implementation in real world deployments.

In general, the resource allocation framework requires (i) a central controller, which is installed on the \gls{iab}-donor, or could be deployed in a \gls{ric} following the O-RAN architecture~\cite{bonati2020open}; and (ii) a scheduler which exchanges resource coordination information with the former. %and computes the weights for the resource allocation.
In particular, and referring to the aforementioned phases of the proposed scheme, the following %communication overhead, computational complexity and implementation  
additional considerations can be made. 

% Might be of interest and/or relevant
% In particular, \gls{rlc} bearers are independently setup for each hop in the \gls{iab}-network and an above-\gls{pdcp} adaptation layer forwards the various packet to either the access or the backhaul \gls{pdcp}s. Therefore, \textit{MmWaveIabNetDevice}s exhibit all the L2 \gls{5g} stack layers up to and including the latter, as can be seen in Fig.~\ref{Fig:mmWaveIabNetDevice}.

\paragraph{Initial setup}
%The setup of the various centralized mechanisms is subdivided into two sub-phases: an initial configuration, where the relevant entities are initialized, and a periodic update of the topology information.
%The initial configuration . 
During this phase, which takes place when the \gls{iab}-nodes perform their first connection to the network, the controller acquires preliminary topology information by leveraging the configuration messages which are already exchanged during the typical Rel.16 \gls{ia} procedure~\cite[Section 9.6]{3gpp_38_874}. Therefore, no additional overhead is introduced. 
Specifically, a map which associates each \gls{iab}-node in the network to a list of its edges, identified by global identifiers (which from now on will be referred to as ``IDs"), is computed. %Since this phase takes place when no \gls{ue} has performed its \gls{ia} procedure yet, the exchanged topology information concerns the donor and \gls{iab}-nodes only.
As a consequence, $\mathcal{O} \left( \vert V \vert \right) $ insertions in a sorted map are performed and this one-time setup exhibits a computational complexity of $\mathcal{O} \left( \vert V \vert \log( \vert V \vert ) \right) $.

\paragraph{Information collection}
The generation of the feedback information is performed in a distributed manner by  the \glspl{gnb}. To such end, the current implementation features the forwarding of information on the channel quality and buffer status, in the form of \glspl{cqi} and \glspl{bsr} respectively. This choice is driven by both the will of maximizing the re-utilization of the \gls{nr} Rel.16 specifications and the goal of making use of \gls{mac}-level \glspl{ce} only, hence avoiding the introduction of any constraint regarding the supported \gls{iab}-relaying architecture.
% Not so relevant for real deployments
%This periodic feedback to the controller is started by the \texttt{Do\-Sched\-Trigger\-Req} method of the various \texttt{MmWave\-RrIab\-Mac\-Scheduler} instances, which in turn calls the \texttt{Gen\-Cumulative\-Map} methods each subframe. However, the central controller can periodically discard the received feedback; by leveraging this possibility, the information collection can be configured to exhibit a period of $T_{collect} > 1$ subframes. 
In particular, the \gls{cqi} and \gls{bsr} information is generated by analyzing the corresponding \glspl{ce}, which are already received by the scheduler of each \gls{gnb}, and checking whether the source \gls{rnti} belongs to an \gls{iab}-node or to a \gls{ue}. In the first case, the corresponding ID
%\footnote{This change of identifiers is extremely important, as \gls{rnti}s are unique only within the scope of the \gls{gnb} they are attached to. Conversely, the IDs are globally unambiguous by design, hence suited for identifying terminals which may be connected to different \gls{gnb}s. \textbf{TODO: is this footnote necessary?}} 
is retrieved and an entry carrying such identifier along with its \gls{cqi}/\gls{bsr} value is generated. 
The feedback information concerning the \glspl{ue}, instead, is averaged in the case of the \glspl{cqi} and added up for the \glspl{bsr}, to obtain a single value for each \glspl{gnb}.
%It can be noted that both \glspl{cqi} and \glspl{bsr} are available to the scheduler, since the UL buffer statuses are already periodically reported by the downstream nodes via their \gls{bsr}s and the DL statuses can be easily retrieved by the former, since the \gls{rlc} buffers reside on the same node as the scheduler itself, i.e., the \gls{gnb}.

Referring to the \gls{3gpp} specifications of~\cite{3gpp_38_321}, the buffers occupancy can then be forwarded to the \gls{iab}-donor by introducing a Short \gls{bsr}, which carries a single \gls{lcg} ID and its respective buffer size. This is motivated by the fact that we do not keep track of per-flow information, i.e., we aggregate all the different \gls{rlc} bearers into a single measurement report. 
Similarly, the channel qualities can be reported by the various \gls{iab}-nodes via an additional \gls{cqi}-only \gls{csi} report, based on a \gls{wb} measurement. Therefore, we can upper bound the size of these \glspl{ce} as 11~\cite{3gpp_38_321} and 7 bits~\cite{3gpp_r1_1713763} respectively. 
%Both additional \glspl{ce} leverage pre-existing \gls{nr} measurements: the main novelty would be the introduction of their periodic reporting to the \gls{iab}-donor. 
%To such end, the \gls{5g} \gls{cqi} and \gls{bsr} data-structures require an additional field which carries the ID, if the chosen \gls{iab}-relaying architecture does not feature an Adaptation Layer~\cite{3gpp_38_874}. Conversely, relaying solutions which support the latter can reuse the \gls{nr} \glspl{ce} and let such layer introduce an additional header.
Regarding the computational complexity, in this phase we generate, at each \gls{gnb}, one \gls{cqi} and one \gls{bsr} for each backhaul link, and (possibly) compute one cumulative \gls{cqi} and \gls{bsr} for the \glspl{ue}. Therefore, the asymptotic complexity of this phase can be identified as $ \mathcal{O} \left(\vert V \vert \right)$.

\paragraph{Centralized scheduling indication}
\label{Sec:cent_indic}
During this phase, the controller makes use of the feedback received from the \glspl{gnb} to update the topology information, compute the weights of the various network links and to generate the centralized scheduling indications. 

Regarding the former, no additional control information is required. In fact, the periodic feedback received from the various \gls{iab}-nodes, which carries a list of ID-value pairs, can be used in such regard. In particular, the controller checks the child-parent associations for discrepancies with its local knowledge, and, if so, updates the stored associations. Discrepancies can arise under two circumstances: the connection of the first \gls{ue} to an \gls{iab}-node and the handover to a different parent of any \gls{iab}-node. In the first case, just the corresponding ``cumulative access node'' needs to be added to the aforementioned map. On the other hand, whenever a backhaul link changes, the topological information for the whole subtending tree must be updated. Since in the worst case this might require an update of the whole map, the asymptotic complexity of the topology information update is $\mathcal{O} \left( \vert V \vert \right) $. Thanks to this periodic update, our framework is robust with respect to \glspl{rlf} and handovers, which may occur due to blockages or mobility of \glspl{ue} and, possibly, \glspl{gnb}.

With respect to the computation of weights for the \gls{mwm} problem, we propose the following policies:

\begin{enumerate}
\item \textbf{\gls{msr}}. 
This policy maximizes the overall \gls{phy}-layer throughput, i.e., the utility function is 
\[ f_u^{\mathrm{MSR}} \mathop = \limits^{\Delta} \, \sum_{e_{i \to k} \, \in \, \mathbf{E^*}} c_{i, \, k}, \]
 and the weight assigned to the edge from node $i$ to node $k$ reads $w_{i, \, k} \mathop = \limits^{\Delta} \, c_{i, \, k}$, where $c_{i, \, k}$ is the capacity of the link $e_{i \to k}$.
\item \textbf{\gls{ba}}.
This resource partitioning strategy aims at avoiding congestion. Therefore, the system utility is:
\[ f_u^{\mathrm{BA}} \mathop = \limits^{\Delta} \, \sum_{e_{i \to k} \, \in \, \mathbf{E^*}} q_{i, \, k}, \]
where the weight $w_{i, \, k}$ reads $q_{i, \, k}$, namely, the amount of buffered data which would reach its next hop in the \gls{iab} network by crossing the link $e_{i \to k}$.
\item \textbf{\gls{mrba}}. 
This represents the most balanced option among the three, since it exploits favorable channel conditions while also preventing network congestion and favoring network fairness. The weight assigned to link $e_{i \to k}$ is:
\[ w_{i, \, k} \mathop = \limits^{\Delta} \, c_{i, \, k} + \eta \cdot q_{i, \, k} \cdot \left( \frac{\mu}{\mu_{thr}} \right)^{k}, \]
where $\eta$, $\, \mu_{thr}$ and $k$ are arbitrary parameters and $\mu$ represents the number of subframes which have elapsed since the last time edge $e_{i \to k}$ has been marked as favored.
\end{enumerate}
Regardless of the specific policy used, the computation of the weights exhibits a complexity which is linear in the number of edges $\vert E \vert$.

Once the weights are computed, the controller obtains an \gls{mwm} of the network via an implementation of the aforementioned \texttt{T-MWM}. The algorithm outputs the activation set $\mathbf{E^*}$, i.e., a map associating the ID of the parent \glspl{gnb} to the one of their favored downstream node. Moreover, $\mathbf{E^*}$ is also used by the controller in order to keep track of which link has not been favored and for how long; this information may then be used to introduce a weight prediction mechanism, improving the robustness of the scheme with respect to the information collection period. 
In terms of overhead, the reporting of $\mathbf{E^*}$ to the \glspl{gnb} would feature as payload just one C-\gls{rnti} per \gls{iab}-node (at most, since some nodes might not receive any whenever they are not active in the specific \gls{mwm} solution). In fact, by exploiting the \gls{bap}, we can encapsulate this payload as part of a \gls{bap} message, while the destination node is already included as part of the \gls{bap} header in the ``\gls{bap} destination'' field. Therefore, the payload size of the scheduling indications is 16 bits. 

Finally, based on the previous considerations and the analysis of Section~\ref{Sec:T-MWM}, the overall complexity of this phase is $ \mathcal{O} \left( \vert E \vert + \vert E \vert + \vert V \vert \right)$, which, when considering \gls{st} topologies, is perfectly equivalent to $ \mathcal{O} \left(  \vert V \vert \right)$.

\paragraph{Distributed scheduling allocation}
The last phase of the resource allocation procedure consists in the distributed \gls{mac}-level scheduling. Before assigning the available resources, the various schedulers check whether any indication has been received from the controller. Based on this condition, the buffer occupancy information is then split into two groups.
The first contains the \gls{bsr}s related to the favored \gls{rnti} (if any), with the caveat that if the latter indicates the cumulative access link, then this set contains the \gls{bsr}s of all the \gls{ue}s attached to the host \gls{gnb}, while the other comprises the remaining control information.
The resource allocation process is then undertaken twice: first considering the set of favored \gls{bsr}s only, then the remainder of these \glspl{ce}. 
Thanks to this repeated allocation, the favored link(s) is (are) scheduled with the highest priority, while the rest of the network only gets the remaining resources. In such a way, the information received by the controller is actually used as an \textbf{indication} and not as the eventual \textbf{resource allocation}. For instance, the \glspl{gnb} are free to override these indications whenever the buffer of the favored child is actually empty, due to discrepancies between its actual status and the related information available to the controller. Moreover, the actual \glspl{dci} can then be generated by the various \glspl{gnb} themselves (instead of being generated only by the controller and then forwarded to the \gls{iab}-nodes), hence making use of the most updated information on the channel quality and buffer status as well. In fact, the exchange of information between the \gls{iab}-nodes and the \gls{iab}-donor introduces an inevitable delay, proportional to their distance in terms of wireless hops, between the generation of the control information at a given node (\glspl{bsr} and/or \glspl{cqi}) and the reception of the corresponding scheduling indications computed by the controller. Thanks to the aforementioned architecture, we limit quite significantly the performance degradation caused by these possible discrepancies between the actual nodes statuses and the (slightly outdated) information which the controller holds about them.

The computational complexity of this last phase is different from the baseline, since it requires an additional \gls{mac}-level resource allocation. However, the specific impact of this modification is difficult to determine, since the choice of the scheduling algorithm is not part of the \gls{nr} specifications. Anyhow, it is reasonable to assume such algorithm to exhibit an asymptotic complexity which is at least linear in the number of users $N$ to be scheduled, i.e., the number of computational steps is $ \mathcal{O} \left( N^{\alpha} \right) \, | \, N \in \mathbb{N}^+ ; \, \alpha \in \mathbb{R}, \, \alpha \geq 1$. Furthermore, it can be observed that in our framework, the two allocations receive as input disjoint subsets of the links; let $\hat{N}, \bar{N} \,\, | \,\, \hat{N}, \bar{N} \in \mathbb{N}; \hat{N} + \bar{N} = N$ be their respective sizes. Therefore, 
the number of operations required for the scheduling can be estimated as $ \mathcal{O} \left( (\hat{N} + \bar{N})^{\alpha} \right)$ for the typical network operation and $ \mathcal{O} \left( \hat{N}^{\alpha} + \bar{N}^{\alpha} \right) $ when using our framework. Since the following holds:
\begin{align*}
(\hat{N} + \bar{N})^{\alpha} & \geq \hat{N}^{\alpha} + \bar{N}^{\alpha} \,\,\, \forall \, \alpha \in \mathbb{N}^+
\end{align*}
we can claim that, under the aforementioned assumptions, the last phase of the proposed framework introduces no computational overhead with respect to the typical network operation.

In addition of the previous considerations, we also need to take into account that, if no modifications to the Rel.~16 \gls{nr} specifications are introduced, a set of \gls{mac} and \gls{bap} headers would also be added to the aforementioned payload estimates; their respective sizes can be estimated as 16~\cite{3gpp_38_321} and 46~\cite{3gpp_38_340} bits, respectively. Accordingly, the worst-case \textit{overall} network overhead can be estimated as follows.
During phase 2, for each backhaul link in the network and towards the controller, up to two \glspl{bsr} and \glspl{cqi} are exchanged, originating from the link's parent and child respectively. Moreover, for each \gls{iab}-node in the network, one \gls{bsr} and one \gls{cqi} are exchanged for the (possible) ``cumulative'' access link. Then, in phase 3 the controller sends up to one scheduling indication per \gls{iab}-node. Letting then $N$ be the number of \gls{iab}-nodes which are connected to the same \gls{iab}-donor, the communication overhead can be upper bounded by $N \cdot (2 + 1) \cdot (65 + 69)$ = $402 \cdot N$ [bits] in the UL and $76 \cdot N$ [bits] in the DL.

% reported in response to R1 C1
Notably, the \gls{3gpp} also considered the possibility of realizing heterogeneous \gls{iab} deployments \cite{3gpp_38_874}, in which \gls{iab}-nodes hold an additional connection with a macro cell (ideally co-located with the \gls{iab}-donor) to handle the control plane. 
In this context, our framework can be enhanced by carrying feedback information (i.e., \glspl{cqi} and \glspl{bsr}) and scheduling indications over the additional connection, reducing the overhead and avoiding the need to travel through multiple hops before reaching the \gls{iab}-donor.

We implemented the proposed resource allocation scheme in the popular open source simulator ns-3, exploiting the \gls{mmwave} module~\cite{mezzavilla2018end} and its \gls{iab} extension~\cite{polese2018end}, to characterize the system-level performance of the proposed solution with realistic protocol stacks, scenarios, and user applications.

The ns-3 \gls{mmwave} module is based on~\cite{baldo2011open} and features highly customizable \gls{phy} and \gls{mac} layer implementations, with an NR-like flexible \gls{ofdm} numerology and frame structure.
It also includes accurate interference and error models, as well as a detailed channel model, which is compliant with the \gls{3gpp} specifications~\cite{zugno2020implementation} and accounts for large and small scale fading phenomena, as well as for interference.
Additionally, the \gls{iab} module~\cite{polese2018end} models wireless relaying functionalities which mimic the specifications presented in~\cite{3gpp_38_874}. Specifically, this module supports both single and multi-hop deployment scenarios, auto-configuration (within the network) of the \gls{iab}-nodes and a detailed \gls{3gpp} protocol stack, allowing wireless researchers to perform system-level analyses of \gls{iab} systems in ns-3.

It is of particular relevance to understand how the scheduling operations are implemented in the \gls{iab} module, since they offer not only the baseline for the proposed scheme, but also valid guidelines for real-world deployments. 
The current ns-3 \gls{iab} schedulers exhibit a \gls{tdma}-based multiplexing between the access and backhaul interfaces. Moreover, scheduling decisions are undertaken in a distributed manner across the \gls{iab} network, i.e., each \gls{gnb} allocates the resources which its access interface offers (to both \gls{ue}s and  \gls{iab}-nodes) independently of the other \gls{gnb}s in the network. 
% performed by the various \gls{gnb}s
In fact, in an \gls{iab} network these scheduling decisions are \textit{almost} independent of one another: if a parent node schedules the backhaul interface of a downstream node, clearly the latter will be constrained in its own scheduling decisions, as it will not be allowed to allocate the time resources which have already been scheduled for backhaul transmissions by its parent. Therefore, in a tree-based, multi-hop wireless network the various \glspl{gnb} need to know in advance the scheduling decisions performed by their upstream nodes: to solve this problem, the authors of the \gls{iab} module for ns-3 introduced a ``\textit{look-ahead backhaul-aware scheduling mechanism}"~\cite{polese2018end}. 
Such mechanism features an exchange of \gls{dci} between the access and backhaul interfaces: in such a way, any time resources already scheduled by the parent for backhaul communications can be marked as such by the corresponding downstream node, preventing any overlap with other transmissions.
Furthermore, the \textit{look-ahead} mechanism requires the schedulers of the various \gls{gnb}s to commit to their resource allocation for a given time $T$ at a time $T - k$, where $k - 1$ is the maximum distance (in terms of wireless hops) of any node from the donor. In such a way, the \gls{dci}s will have time to propagate across the \gls{iab} network and reach the farthest node at time $T - 1$, thus allowing its scheduler to perform the resource allocation process at least one radio subframe in advance.

%\begin{figure}[tbp]
%%\captionsetup{singlelinecheck=false, justification=justified}
%\centering
%\includegraphics[width=0.75\linewidth]{IabSchedAlloc.pdf}
%\caption{Baseline distributed scheduler: example of a resource allocation at time $T$, for the depicted reference topology and where $k - 1$ indicates the maximum depth in the \gls{iab} network. Figure adapted from~\cite{polese2018end}.}
%\label{Fig:iab_sched_alloc}
%\vspace{-.6cm}
%\end{figure}

%An example of this scheduling mechanism is depicted in Fig.~\ref{Fig:iab_sched_alloc}: it can be noted how, for instance, the time resources which the donor has scheduled for backhauling purposes towards \gls{iab}-node 1 are marked as reserved by the latter. As a consequence, such node constraints its resource allocation to the remaining time slots only. 

\subsubsection{Simulation scenario and parameters}
The purpose of these simulations is to understand the performance of the proposed resource partitioning framework in the context of its target deployment, i.e., a multi-hop \gls{iab} network. As a consequence, the reference scenario consists of a dense urban deployment with a single \gls{iab}-donor and multiple \gls{iab}-nodes, as depicted in Fig.~\ref{Fig:Sim_scen}. In particular, the various \glspl{gnb} are distributed along an urban grid where the donor is located at the origin while the \gls{iab}-nodes are deployed along the street intersections, with a minimum inter-site distance of 100 m. The \gls{iab}-nodes attachments are computed using the so-called \textit{HQF} policy presented in~\cite{polese2018iab}; however, this choice does not introduce any loss of generality since such parameter is fixed for all the runs. A given number of \glspl{ue} are deployed within the surroundings of these base stations, with an initial position which is randomly sampled from circles of radius $\rho$ and whose centers are the various \glspl{gnb}. A summary of the simulation parameters in provided in Tab.~\ref{Tab:Sim_params}.
%Notably, the choice of not considering mobile \glspl{ue} is driven exclusively by concerns regarding the time needed to run our simulation campaigns. In fact, our framework introduces no limitations in such regard, due to the way the \gls{iab} topology is retrieved and the fact that we do not keep track of the per-flow information.
%The lack of mobility is mainly driven by concerns over the computational complexity of the simulations. 

\begin{figure}[tbp]
    \centering
    \subfloat[A realization of the simulation scenario; the dotted lines represent the cell-attachments of the \gls{iab}-nodes.\label{Fig:Sim_scen}]{
     % this sets the width of the figure, adjust to your needs
     \setlength\fwidth{0.45\columnwidth}
     % this sets the height of the figure, adjust to your needs
     \setlength\fheight{0.35\columnwidth}
       \raisebox{-.5\height}{\input{Figures/CentralResourceManagement/Sim_scenario.tex}}
    }\hfill
    \subfloat[Simulation parameters.\label{Tab:Sim_params}]{
    \footnotesize
   \begin{tabular}{cc}
   \multicolumn{2}{c}{\textsc{Simulation parameters}}\\
   \hline
   \textsc{Parameter} & \textsc{Value} \\
   \hline
   Number of runs $N_{runs}$ & 25  \\
   \rowcolor{gray!15} Simulation time $T_{sim}$ & 3 s \\
   \gls{mwm} period $T_{alloc}$ & $\{ 1, 2, 4\}$ subframes \\
   \rowcolor{gray!15} Layer 4 protocol & $\{ $UDP, TCP$ \}$ \\
   UDP packet size $s_{UDP}$ & $\{50, 100, 200, 500 \}$ B \\
   \rowcolor{gray!15} Weight policy $f_u$ & $\{$\gls{msr}, \gls{ba}, \gls{mrba}$\}$ \\
   \hline
   \end{tabular}
    }
    \label{Float:Sim_scen_and_params}
    \caption{Simulation configuration.}
    \vspace{-.6cm}
\end{figure}

\subsection{Performance evaluation}
\label{Sec:perf_eval}

\begin{figure}[tbp]
	\centering
	%\captionsetup{singlelinecheck=false, justification=justified}
  % this sets the width of the figure, adjust to your needs
  	\subfloat[$s_{UDP}$ = 100 B, i.e., \gls{udp} rate of 8 Mbps.\label{Fig:Thr_ECDF_100}]{
  	\setlength\fwidth{0.68\columnwidth}
    % this sets the height of the figure, adjust to your needs
    \setlength\fheight{0.27\columnwidth}
    \input{Figures/CentralResourceManagement/Sim_results_v2/E2E_throughput_ECDF_packet_size_100.tex}
  	}
  	\hfill
  	\subfloat[$s_{UDP}$ = 500 B, i.e., \gls{udp} rate of 40 Mbps.\label{Fig:Thr_ECDF_500}]{
  	% this sets the width of the figure, adjust to your needs
    \setlength\fwidth{0.68\columnwidth}
    % this sets the height of the figure, adjust to your needs
    \setlength\fheight{0.27\columnwidth}
    \input{Figures/CentralResourceManagement/Sim_results_v2/E2E_throughput_ECDF_packet_size_500.tex}
  	}
    \caption{Per-\gls{ue} end-to-end throughput \glspl{ecdf}. The thick dashed line represents the rate of the \gls{udp} sources.}
    \label{Fig:thr_ECDF}   
    \vspace{-.6cm} 
\end{figure}

Both the \gls{iab}-donor and the \gls{iab}-nodes are equipped with a phased array featuring 64 antenna elements, and transmit with a power of 33 dBm; conversely \glspl{ue} are equipped with 16 antenna elements and their transmission power is restricted to 23 dBm. Notably, the presence of additional antenna elements at the \glspl{gnb} is a key (but reasonable) assumption, as it allows base stations to achieve a high beamforming gain. In turn, it is possible to achieve a high capacity, which is fundamental to avoid performance bottlenecks, given the absence of a fiber backhaul.
The \glspl{ue} download data which originates from sources that are installed on a remote host; both the \gls{udp} and the \gls{tcp} are used. For the \gls{udp} simulations, the rate of the sources is varied from 4 to 40 Mbps to introduce different degrees of saturation in the network. Therefore, in these simulations only DL traffic is considered.
Finally, the performance of the proposed policies is hereby compared with the baseline of~\cite{polese2018end}, indicated as ``Dist.'' by examining end-to-end throughput, latency, and a network congestion metric.

\subsubsection{Throughput}
\label{subsec_thr}

The first metric which is inspected in this analysis is the end-to-end throughput at the application layer. As a consequence, only the packets which are correctly received at the uppermost layer of the destination node in the network are taken into account. In particular, for each \gls{ue} and each simulation run, the long-term average throughput is computed as follows:
\[ S^{\mathrm{APP}}_{k, n} \mathop = \limits^{\Delta} \, \frac{B(T_{sim}, k, n)}{T_{sim}} \]
where $B(T, k, n)$ is the cumulative number of bits received up to time $T$ by the $k$-th \gls{ue}, during the $n$-th simulation run. Then, the distribution of 
$\mathbf{S}^{\mathrm{APP}}$, namely, the vector containing the collection of the $S^{\mathrm{APP}}_{k, n}$ values across the different runs and \glspl{ue}, is analyzed.

Figs.~\ref{Fig:Thr_ECDF_100} and~\ref{Fig:Thr_ECDF_500} report the \gls{ecdf} of $\mathbf{S}^{\mathrm{APP}}$, for a \gls{udp} packet size of 100 and 500 bytes, respectively, and the policies introduced in Section~\ref{Sec:ns3-impl}. In the former, we can notice that the introduction of the semi-centralized framework increases by up to 15\% the percentage of \glspl{ue} whose throughput almost matches the rate of the \gls{udp} sources, i.e., achieving approximately 7.9~Mbps.
Moreover, by focusing on the leftmost portion of Fig.~\ref{Fig:Thr_ECDF_100} we can observe another interesting result, concerning the throughput experienced by the \glspl{ue} which do not fulfill their \gls{qos} requirements. In fact, with respect to the first quartile the distributed scheduler and the \gls{msr} policy achieve the worse performance.
% with 25\% of the \glspl{ue} obtaining a throughput smaller than 3.4~Mbps. 
On the other hand, the \gls{mrba} and \gls{ba} policies significantly improve these results, even though the extent of such improvements varies quite dramatically across the two.

%Compared with the distributed case, the \gls{msr} policy achieves a higher throughput with respect to all the percentiles, albeit exhibiting the same high variance of the former.
In particular, compared with the distributed case the \gls{ba} and \gls{mrba} policies introduce a 2 and 3-fold increase of the worst case throughput respectively, coupled with a significantly lower variance in both cases. 

These results can be explained as follows: since a \gls{udp} packet size of 100 bytes does not saturate the capacity of the access links, the main performance bottleneck of this configuration is represented by the buffering of the aggregated traffic on the intermediate backhaul links. Therefore, the \gls{msr} policy provides no improvements compared to the performance of the distributed scheduler, since it simply favors the links which exhibit a higher \gls{sinr}. Conversely, the prioritization of the most congested links which is introduced by the other two strategies successfully tackles the former problem. 
In particular, the \gls{ba} policy exhibits the highest worst case throughput, while also satisfying the \gls{qos} requirements of approximately 40\% of the \glspl{ue}. Moreover, the bias towards high \gls{sinr} channels introduced by the \gls{mrba} strategy further improves the higher percentiles, compared to the \gls{ba} policy, and dramatically outperforms \gls{msr} and the baseline across all percentiles. 
% which is better ? 
\begin{figure*}[tbp]
  \centering
%\captionsetup[subfigure]{justification=centering}
  \subfloat[First quartile.\label{Fig:Throughput_first_quartile}]{
    % this sets the width of the figure, adjust to your needs
    \setlength\fwidth{0.65\columnwidth}
    % this sets the height of the figure, adjust to your needs
    \setlength\fheight{0.28\columnwidth}
    \input{Figures/CentralResourceManagement/Sim_results_v2/E2E_first_quartile_throughput.tex}
	}
  \hfill
\subfloat[Third quartile.\label{Fig:Throughput_third_quartile}]{
    % this sets the width of the figure, adjust to your needs
    \setlength\fwidth{0.65\columnwidth}
    % this sets the height of the figure, adjust to your needs
    \setlength\fheight{0.28\columnwidth}
    \input{Figures/CentralResourceManagement/Sim_results_v2/E2E_third_quartile_throughput.tex}
	}
  %\captionsetup{singlelinecheck=false, justification=justified}
  %\vspace*{-3mm}
   \caption{End-to-end throughput quartiles, for $s_{UDP}$ $\in$ $\{50, 100, 200, 500 \}$ B.}
  \label{Fig:Throughput_quartiles}
  \vspace{-.6cm} 
\end{figure*}
%TODO Remove this and keep just ECDF of 100B and third quartiles

By increasing the \gls{udp} packet size to 500 bytes, the network becomes noticeably saturated, as depicted by Fig.~\ref{Fig:Thr_ECDF_500}; in fact, in this instance only a minority of the \glspl{ue} achieves a throughput which is comparable to the source rate. With this configuration, the \gls{ba} strategy achieves the worst performance, providing a significantly lower throughput across most percentiles. On the other hand, the remaining strategies both introduce significant improvements, although with different trade-offs. In particular, compared to distributed case, the \gls{msr} policy exhibits an increase of approximately 20\% of the number of \glspl{ue} which satisfy their \gls{qos} requirements, albeit at the cost of worse lower percentiles. The \gls{mrba}, conversely, introduces performance benefits which mostly affect the bottom percentiles only. However, with this strategy only a limited portion of the \glspl{ue} achieves the target throughput of 40 Mbps. 
As a consequence, we can conclude that with the configuration depicted in Fig.~\ref{Fig:Thr_ECDF_500} the network is approaching the capacity of the \gls{mmwave} channels. Therefore, buffering phenomena are likely occurring at each intermediate \gls{iab}-node. Moreover, we can say that in a saturated network the congestion is so severe that prioritizing the bottleneck links is not enough: we also need to take into account the channel conditions and prioritize the links which not only are congested, but also have the ``biggest chance" of getting rid of the buffered data due to the temporary better channel quality.

Finally, Fig.~\ref{Fig:Throughput_quartiles} presents the first and third quartiles of $\mathbf{S}^{\mathrm{APP}}$ as a function of the \gls{udp} packet size $s_{UDP}$. It can be noted that, with respect to the first quartile, the \gls{mrba} outperforms all the other policies by delivering a throughput which is up to 90\% higher than the one obtained by the distributed scheduler. On the other hand, Fig.~\ref{Fig:Throughput_third_quartile} shows how the best third quartile is achieved by \gls{msr}, with up to a 2-fold improvement over the distributed solution. 
Furthermore, we can observe how the positive impact of the \gls{ba} strategy is inversely proportional to the saturation in the network. We can then conclude that the bias it introduces loses its effectiveness as the buffering phenomena start to affect the majority of the \gls{iab}-nodes.

\subsubsection{Latency}

Just like the aforementioned metric, the latency is measured end-to-end at the application layer. Thanks to this choice, the resulting delay accurately represents the system-level performance, as it includes the latency which is introduced at each hop in the \gls{iab} network.

In particular, for each packet correctly received at the uppermost layer of its final destination, the following quantity is traced:
\[ D^{\mathrm{APP}}_{i} \mathop = \limits^{\Delta} \, \sum_{l_k \, \in \, \mathcal{E}_{i}} D^{l_k}_i \] 
where $\mathcal{E}_{i}$  comprises the links in the \gls{iab} network that are crossed by the $i$-th packet, while the term $D^{l_k}_i$ indicates its point-to-point latency over the path link $l_i$. 
Finally, these values are collected for each of the various runs into the vector $\mathbf{D}^{\mathrm{APP}}$ and its statistical properties are inspected.

Fig.~\ref{Fig:Del_ECDF_100} shows the empirical \gls{ecdf} of $\mathbf{D}^{\mathrm{APP}}$ for a packet size of 100 bytes. It can be noticed that, in this case, the 90th percentile achieved by the \gls{ba} and the \gls{mrba} policies are approximately 20 \% smaller than the one obtained by the distributed scheduler. Moreover, these strategies manage to dramatically reduce the number of packets received with extremely high delay, i.e., in the order of seconds, showing the dramatic impact of buffering in the baseline configuration. Conversely, the \gls{msr} policy provides the best performance with respect to the best case delay only, although it still outperforms quite  significantly the distributed strategy. 

These trends are exacerbated by Fig.~\ref{Fig:Delay_third_quartile}, which shows the third quartile of $\mathbf{D}^{\mathrm{APP}}$ as a function of the \gls{udp} packet size $s_{UDP}$. In fact, we can notice that the effectiveness of the \gls{ba} policy is inversely proportional to the network saturation; the opposite holds true with respect to the \gls{msr} strategy. It follows that, for \gls{udp} rates in the order of 5 to 10 Mbps, the network is mainly plagued by local congestion which causes the insurgence of buffering in some of the nodes. Conversely, as the rate of the \gls{udp} sources increases the system shifts to a capacity-limited regime, a phenomenon which explains the dominance of the \gls{msr} and \gls{mrba} policies.

\begin{figure*}[tbp]
%\captionsetup[subfigure]{justification=centering}
%  \subfloat[ECDF, for $s_{UDP}$ = 200 B.\label{Fig:Del_ECDF_200}]{
%    % this sets the width of the figure, adjust to your needs
%    \setlength\fwidth{0.48\columnwidth}
%    % this sets the height of the figure, adjust to your needs
%    \setlength\fheight{0.25\columnwidth}
%    \input{Figures/CentralResourceManagement/Sim_results/E2E_delay_ECDF_packet_size_200.tex}
%    }
%  \hfill
	\centering
	%\captionsetup{singlelinecheck=false, justification=justified}
    \subfloat[ECDF, for $s_{UDP}$ = 100 B.\label{Fig:Del_ECDF_100}]{
     % this sets the width of the figure, adjust to your needs
    \setlength\fwidth{0.65\columnwidth}
    % this sets the height of the figure, adjust to your needs
    \setlength\fheight{0.28\columnwidth}
    \input{Figures/CentralResourceManagement/Sim_results_v2/E2E_delay_ECDF_packet_size_100.tex}
    }
    \hfill
    \centering
  \subfloat[Third quartile, for $s_{UDP}$ $\in$ $\{50, 100, 200, 500 \}$ B.\label{Fig:Delay_third_quartile}]{
    % this sets the width of the figure, adjust to your needs
    \setlength\fwidth{0.65\columnwidth}
    % this sets the height of the figure, adjust to your needs
    \setlength\fheight{0.28\columnwidth}
     \input{Figures/CentralResourceManagement/Sim_results_v2/E2E_third_quartile_delay.tex}
    }
  %\captionsetup[figure]{singlelinecheck=false, justification=justified}
  %\vspace*{-3mm}
   \caption{Per-\gls{ue} end-to-end delay statistics.}
  \label{Fig:Delay_stats}
    \vspace{-.6cm} 
\end{figure*}

\begin{figure*}[tbp]
\centering
%\captionsetup[subfigure]{justification=centering}
  \subfloat[Medians, toward \glspl{ue}.\label{Fig:BSR_median_ue}]{
    % this sets the width of the figure, adjust to your needs
    \setlength\fwidth{0.23\columnwidth}
    % this sets the height of the figure, adjust to your needs
    \setlength\fheight{0.28\columnwidth}
    \input{Figures/CentralResourceManagement/Sim_results_v2/Median_BSR_UE.tex}
    }
  \subfloat[Medians, toward \\ \gls{iab}-nodes.\label{Fig:BSR_median_node}]{
    % this sets the width of the figure, adjust to your needs
    \setlength\fwidth{0.23\columnwidth}
    % this sets the height of the figure, adjust to your needs
    \setlength\fheight{0.28\columnwidth}
    \input{Figures/CentralResourceManagement/Sim_results_v2/Median_BSR_node.tex}
    }
  \subfloat[Third quartile vs. depth in the \gls{iab} network, for $s_{UDP}$ = 200 B.\label{Fig:BSR_third_quartile_depth}]{
    % this sets the width of the figure, adjust to your needs
    \setlength\fwidth{0.23\columnwidth}
    % this sets the height of the figure, adjust to your needs
    \setlength\fheight{0.28\columnwidth}
    \input{Figures/CentralResourceManagement/Sim_results_v2/Third_quartile_BSR_vs_depth.tex}
    }  
  %\captionsetup[figure]{singlelinecheck=false, justification=justified}
  %\vspace*{-3mm}
   \caption{Buffer occupancy statistics, for $s_{UDP}$ $\in$ $\{50, 100, 200, 500 \}$~B.}
  \label{Fig:BSR_median}
    \vspace{-.6cm} 
\end{figure*}

\subsubsection{Network congestion}

The network congestion is measured by collecting, every $T_{alloc}$ subframes, the \gls{rlc} buffers status of the various nodes into the vector $\mathbf{B}^{\mathrm{RLC}}$. It must be noted that, since \gls{rlc} \gls{am} is used, these values will indicate data which is related to both new packets and possible retransmissions.

Figs.~\ref{Fig:BSR_median_ue} and~\ref{Fig:BSR_median_node} show the median of $\mathbf{B}^{\mathrm{RLC}}$, for traffic flows whose next hop in the network is represented by either \glspl{ue} or \gls{iab}-nodes respectively. Specifically, the \gls{ba} strategy achieves the worst performance in this metric, leading to unstable systems in the cases of $s_{UDP}$ = $\{$200, 500$\}$ B. 
%In fact, as soon as the capacity of the point-to-point channels becomes a limiting factor, prioritizing the most congested links without taking into account their quality fails to prevent the insurgence of buffering phenomena, especially towards other \glspl{gnb}. 
A reason for this behavior can be found in the ``locality" of the \gls{ba} policy criteria and the lack of influence of the past allocations on the weights. These characteristics may lead to favoring the same link in a repeated manner, hence offering little remedy to the end-to-end congestion.

On the other hand, the buffer occupancy achieved by the \gls{msr} strategy depicts an effectiveness which, in accordance with previous observations, is proportional with respect to the source rate. In particular, a dramatic decrease of up to 4 orders of magnitude is achieved for $s_{UDP} = 500$~B.
Finally, when compared to the distributed scheduler, the \gls{mrba} policy also achieves a lower median \gls{rlc} buffer occupancy towards the backhaul links, albeit the difference is less striking than in the case of the \gls{msr} policy, and at the cost of slightly more congested \gls{ue} buffers. 
%Furthermore, similar trends, albeit less pronounced, can be found in Fig.~\ref{Fig:BSR_third_quartile_node} with respect to the third quartiles.
% These results can be explained by the fact that the \gls{mrba} is essentially a blend of the other two centralized policies,

Additionally, Fig.~\ref{Fig:BSR_third_quartile_depth} depicts the third quartiles of $\mathbf{B}^{\mathrm{RLC}}$ as a function of the depth of the corresponding \gls{gnb} in the \gls{iab} network. It is possible to notice that, regardless of the policy in use, the amount of buffering at the various \glspl{gnb} generally decreases as their distance to the donor increases. This follows from the fact that nodes which have a lower depth exhibit, on average, a bigger subtending tree; therefore the amount of traffic which makes use of their backhaul links is significantly higher.
%As a consequence, we can further re-iterate the assumption that the major performance bottleneck of the system is represented by the congestion among the various \gls{iab}-nodes.




\subsubsection{Performance with TCP traffic}

%\begin{figure}[h!]
%\centering
%%\captionsetup[subfigure]{justification=centering}
%  \subfloat[Toward \glspl{ue}.\label{Fig:TCP_BSR_median_ue}]{
%    % this sets the width of the figure, adjust to your needs
%    \setlength\fwidth{0.35\columnwidth}
%    % this sets the height of the figure, adjust to your needs
%    \setlength\fheight{0.2\columnwidth}
%    \input{Figures/CentralResourceManagement/Sim_results/TCP_third_quartile_BSR_vs_depth.tex}
%    }
%  \hfill
%  \subfloat[Toward \gls{iab}-nodes.\label{Fig:TCP_BSR_median_node}]{
%    % this sets the width of the figure, adjust to your needs
%    \setlength\fwidth{0.35\columnwidth}
%    % this sets the height of the figure, adjust to your needs
%    \setlength\fheight{0.2\columnwidth}
%    \input{Figures/CentralResourceManagement/Sim_results/TCP_median_BSR_node.tex}
%    }
%%  \hfill
%%  \subfloat[\gls{iab}-nodes \glspl{bsr} third quartiles.\label{Fig:BSR_third_quartile_node}]{
%%    % this sets the width of the figure, adjust to your needs
%%    \setlength\fwidth{0.2\columnwidth}
%%    % this sets the height of the figure, adjust to your needs
%%    \setlength\fheight{0.2\columnwidth}
%%    \input{Figures/CentralResourceManagement/Sim_results/Third_quartile_BSR_node.tex}
%%    }  
%  %\captionsetup[figure]{singlelinecheck=false, justification=justified}
%  \vspace*{-3mm}
%   \caption{\glspl{bsr} medians, for $s_{TCP}$ $\in$ $\{50, 100, 200, 500 \}$ B}
%  \label{Fig:TCP_BSR_median}
%\end{figure}

This subsection extends the aforementioned analysis by inspecting the performance of the proposed scheme in the case of \gls{tcp} traffic. Specifically, a \gls{tcp} full-buffer source model is used, and the various semi-centralized resource allocation policies are compared against the distributed scheduler.

\begin{figure*}[tbp]
\centering
%\captionsetup[subfigure]{justification=centering}
  \subfloat[Delay \gls{ecdf}.\label{Fig:TCP_delay_ECDF_256}]{
    % this sets the width of the figure, adjust to your needs
    \setlength\fwidth{0.65\columnwidth}
    % this sets the height of the figure, adjust to your needs
    \setlength\fheight{0.28\columnwidth}
    \input{Figures/CentralResourceManagement/Sim_results_v2/TCP_E2E_delay_ECDF_packet_size_256.tex}
    }
  \hfill
  \subfloat[Throughput \gls{ecdf}.\label{Fig:TCP_throughput_ECDF_256}]{
    % this sets the width of the figure, adjust to your needs
    \setlength\fwidth{0.65\columnwidth}
    % this sets the height of the figure, adjust to your needs
    \setlength\fheight{0.28\columnwidth}
    \input{Figures/CentralResourceManagement/Sim_results_v2/TCP_E2E_throughput_ECDF_packet_size_256.tex}
    }
%  \vspace*{-3mm}
   \caption{End-to-end delay and throughput statistics, for \gls{tcp} layer 4 protocol.}
  \label{Fig:TCP_ECDFs}
    \vspace{-.3cm} 

\end{figure*}

Fig.~\ref{Fig:TCP_delay_ECDF_256} shows the \gls{ecdf} of the end-to-end delay experienced by the successfully received packets. Similarly to the \gls{udp} case, the distributed scheduler exhibits the worst results in this regard. In fact, the performance benefits introduced by the semi-centralized policies are noticeable across all percentiles. In particular, with this configuration the \gls{mrba} policy provides the best results, followed quite closely by the \gls{ba} and \gls{msr} strategies. Fig.~\ref{Fig:TCP_throughput_ECDF_256}, which depicts the statistics of the end-to-end throughput achieved by the various \glspl{ue}, further explains the effect on the system of the various semi-centralized policies. In particular, the \gls{ba} policy achieves, approximately, a 45\% increase of the peak throughput. Conversely, the \gls{mrba} strategy causes a redistribution of the achieved data rate, massively improving the lower quartiles (up to the 80-th), albeit at the expense of the maximum throughput. Finally, \gls{msr} also causes a redistribution of the throughput across the different percentiles, but the net benefit is less noticeable.

Therefore, we can conclude that regardless of the specific policies used, the proposed scheme improves the system performance also with this configuration, by limiting the insurgence of local buffering and aiding the end-to-end congestion control mechanism offered by \gls{tcp}. Furthermore, it can be noted that both a prioritization of the most congested links and of the channels featuring a higher quality results in performance benefits in the average case, although it also causes a decrease of the network fairness. On the other hand, the \gls{mrba} policy manages to optimize the backhaul/access resource partitioning, while introducing an increase in the throughput fairness at the same time.

%\begin{figure}[tbp]
%	\centering
%	%\captionsetup[figure]{singlelinecheck=false, justification=justified}
%    % this sets the width of the figure, adjust to your needs
%    \setlength\fwidth{0.6\columnwidth}
%    % this sets the height of the figure, adjust to your needs
%    \setlength\fheight{0.2\columnwidth}
%    \input{Figures/CentralResourceManagement/Sim_results/TCP_vs_UDP.tex}
%   \caption{Comparison of \gls{tcp} and \gls{udp} performance.}
%  \label{Fig:TCP_vs_UDP}
%\end{figure}

\begin{figure*}[tbp]
%\captionsetup[subfigure]{justification=centering}
  \subfloat[Combined per \gls{ue} end-to-end throughput first quartile and delay third quartile, as a function of the semi-centralized allocation period $T_{alloc}$.\label{Fig:Alloc_period_impact}]{
    % this sets the width of the figure, adjust to your needs
    \setlength\fwidth{0.65\columnwidth}
    % this sets the height of the figure, adjust to your needs
    \setlength\fheight{0.28\columnwidth}
    \input{Figures/CentralResourceManagement/Sim_results_v2/Perf_vs_alloc_period.tex}
    }
  \hfill
  \subfloat[\gls{mwm} runtime as a function of the number of \gls{iab}-nodes in the network.\label{Fig:MWM_runtime}]{
    % this sets the width of the figure, adjust to your needs
    \setlength\fwidth{0.65\columnwidth}
    % this sets the height of the figure, adjust to your needs
    \setlength\fheight{0.28\columnwidth}
     \input{Figures/CentralResourceManagement/Sim_results/MWM_runtime_vs_nodes.tex}
    }
  %\captionsetup[figure]{singlelinecheck=false, justification=justified}
  
   \caption{Considerations on the formulated assumptions.}
  \label{Fig:Assump}
      \vspace{-.6cm} 

\end{figure*}

\vspace{-.3cm}
\subsubsection{Further considerations}

It is of particular relevance to analyze the performance of the semi-centralized policies when relaxing the most restrictive hypothesis, i.e., the capability of exchanging feedback information in a timely manner.
Actually, such analysis provides also insights regarding the effects of errors and/or crashes in the control messages. Indeed, both control and data channels implement error detection mechanisms, hence we deem the likelihood of undetected errors in the feedback information to be negligible. As a consequence, the errors would be detected at the receiver, and lost information would be either retransmitted by the source or simply discarded, waiting for the following periodic update; in both cases, the net effect would be a delay in the reception of the message.

To such end, Fig.~\ref{Fig:Alloc_period_impact} shows the performance of the proposed framework as a function of the semi-centralized allocation period $T_{alloc}$. In particular, each of the depicted points represents the joint end-to-end throughput and delay achieved with the different configurations.

As expected, in general the effectiveness of the various semi-centralized policies progressively deteriorates as the frequency of the scheduling indications decreases. Interestingly, the \gls{ba} policy exhibits the lowest performance degradation with respect to an increase of the allocation period, which suggests that this phenomenon has a slower evolution over time compared to the one exhibited by the channels quality. Nevertheless, the key takeaway is that all of the proposed allocation strategies except \gls{msr} outperform the distributed solution, across both metrics. In fact, the latter exhibits the lowest throughput first quartile, but only because it introduces a strong bias towards high \gls{sinr} channels, as discussed in Section~\ref{subsec_thr}. However, the trend depicted by Fig.~\ref{Fig:Alloc_period_impact} also suggests that there exists a threshold value of $T_{alloc}$ after which the performance of the proposed frameworks brings only marginal performance benefits.

Additionally, the running time of the \gls{mwm} algorithm presented in Section~\ref{Sec:T-MWM} was analyzed, in order to understand whether it may partially invalidate the timely feedback assumption. Specifically, Fig.~\ref{Fig:MWM_runtime} presents the statistics of the various \gls{mwm} execution times, obtained on a machine equipped with an i7-6700 4-core processor clocked at 3.4~{GHz}. 
The first observation which can be made is that this empirical analysis confirms the previously estimated asymptotic complexity, depicting a running time which exhibits a linear dependence on the number of \glspl{gnb} in the network. Furthermore, it can be noted that the runtime of the \gls{mwm} algorithm does not exceed 6~$\mu$s, even for a significant number of \gls{iab}-nodes connected to the same \gls{iab}-donor. As a consequence, we can conclude that the execution times of the semi-centralized allocation process do not pose any threat to the timely feedback assumption, since they are reasonably smaller than the duration of the minimum semi-centralized allocation period. 

%\subsection{Conclusions}
%\label{Sec:conc}

In this paper we proposed a semi-centralized resource partitioning scheme for \gls{5g} and beyond \gls{iab} networks, coupled with a set of allocation policies. We showed that the introduction of this light resource allocation cooperation dramatically improves the end-to-end throughput and delay achieved by the system already, preventing (or at the very least limiting) the insurgence of network congestion on the backhaul links. Specifically, the \gls{mrba} policy exhibits the most promising results, offering up to a 3-fold increase in the worst-case throughput and approximately a 30\% smaller worst-case latency, compared to the distributed scheduler. On the other hand, the effectiveness of the \gls{ba} and \gls{msr} policies varies quite significantly across the specific system configuration and inspected metric. %Nevertheless, better than SoA
%TODO Maybe add more detailed results
%TODO Policy 3 -> other policies by tweaking the parameters

We provided considerations on the implementation of a semi-centralized resource allocation controller in real world deployments. In particular, we acknowledged that the proposed scheme relies on the assumption of \gls{iab}-nodes being capable of exchanging timely feedback information with the \gls{iab}-donor. Even though the amount of signaling data which the proposed solution requires is quite low, and its performance is quite robust with respect to an increase of the central allocation period, we argue that this remains a significant constraint. Moreover, such drawback is exacerbated by the unfavorable \glspl{mmwave} propagation characteristics.
As a consequence, we deem that solutions involving a central controller, which rely on timely exchange of control information with the \gls{iab}-donor, are likely to require dedicated control channels, possibly at sub-6~{GHz}, in order to grant the utmost priority and reliability to the feedback information. Therefore, we can conclude that the aforementioned framework can bring dramatic performance benefits to \gls{iab} networks, although its introduction in \gls{5g} and beyond deployments requires additional research efforts.

For this reason, as part of our future work we plan to design machine-learning algorithms which predict the network evolution at the \gls{iab}-donor. This improvement will allow us to relax the timely feedback assumption, by increasing the minimum semi-centralized allocation period which leads to performance benefits over distributed strategies. 
Moreover, we foresee to implement mechanisms which adapt the parameters of the \gls{mrba} policy to the system load and configuration, and additional resource partitioning strategies. 
Finally, the generalization of the proposed framework to \gls{sdma} systems will be studied. 
The use of such multiple access scheme should significantly improve the performance of \gls{mmwave} wireless backhauling by introducing the possibility of concurrently serving multiple terminals, provided that they exhibit a sufficient distance among them.


